{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eed106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/Users/ishanyash17/Downloads/archive/halfhourly_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4845c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert 'tstp' to datetime and extract components\n",
    "    df['datetime'] = pd.to_datetime(df['tstp'])\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    df['month'] = df['datetime'].dt.month_name()\n",
    "    df['day_of_month'] = df['datetime'].dt.day\n",
    "    df['time'] = df['datetime'].dt.time\n",
    "    df['weekday'] = df['datetime'].dt.day_name()\n",
    "    df['day_seconds'] = (df['datetime'] - df['datetime'].dt.normalize()).dt.total_seconds()\n",
    "\n",
    "    # Ordering weekdays and months\n",
    "    df['weekday'] = pd.Categorical(df['weekday'], categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], ordered=True)\n",
    "    df['month'] = pd.Categorical(df['month'], categories=calendar.month_name[1:], ordered=True)\n",
    "\n",
    "    # Set energy consumption data to numeric type\n",
    "    df = df[df[\"energy(kWh/hh)\"] != \"Null\"]\n",
    "    df[\"energy\"] = df[\"energy(kWh/hh)\"].astype(\"float64\")\n",
    "\n",
    "    # Calculate the cumulative energy use over time for each date\n",
    "    df[\"cumulative_sum\"] = df.groupby('date')[\"energy\"].cumsum()\n",
    "\n",
    "    # Setting 'datetime' as the index\n",
    "    df = df.set_index(\"datetime\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf431b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-b674eda62c7a>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"energy\"] = df[\"energy(kWh/hh)\"].astype(\"float64\")\n",
      "<ipython-input-2-b674eda62c7a>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"cumulative_sum\"] = df.groupby('date')[\"energy\"].cumsum()\n",
      "/Users/ishanyash17/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-60ef3fc217d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Save the preprocessed dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprocessed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing file {input_filename}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3385\u001b[0m         )\n\u001b[1;32m   3386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3387\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m             )\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_native_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mto_native_types\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0mformatting\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"to_native_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mto_native_types\u001b[0;34m(self, na_rep, float_format, decimal, quoting, **kwargs)\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the paths\n",
    "input_folder_path = '/Users/ishanyash17/Downloads/archive/halfhourly_dataset/halfhourly_dataset'\n",
    "output_folder_path = '/Users/ishanyash17/Downloads/preprocessed_block_ds'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "for i in range(112):\n",
    "    input_filename = os.path.join(input_folder_path, f\"block_{i}.csv\")\n",
    "    output_filename = os.path.join(output_folder_path, f\"PreProcessed_DS_Block{i}.csv\")\n",
    "    \n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(input_filename)\n",
    "\n",
    "        # Preprocess the dataset\n",
    "        processed_df = preprocess_data(df)\n",
    "\n",
    "        # Save the preprocessed dataset\n",
    "        processed_df.to_csv(output_filename, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {input_filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a7f42e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming all files are in the same directory\n",
    "folder_path = '/Users/ishanyash17/Downloads/preprocessed_block_ds'\n",
    "all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Concatenate all datasets\n",
    "df_all = pd.concat((pd.read_csv(file) for file in all_files), ignore_index=True)\n",
    "\n",
    "# Save the merged dataset\n",
    "df_all.to_csv('/Users/ishanyash17/Downloads/merged_hh_block035_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74dedd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('/Users/ishanyash17/Downloads/merged_hh_block035_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0edd7ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>tstp</th>\n",
       "      <th>energy(kWh/hh)</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_seconds</th>\n",
       "      <th>energy</th>\n",
       "      <th>cumulative_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 10:30:00.0000000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:00:00.0000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:30:00.0000000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>41400.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:00:00.0000000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:30:00.0000000</td>\n",
       "      <td>0.262</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid                         tstp  energy(kWh/hh)        date  \\\n",
       "0  MAC000126  2011-12-15 10:30:00.0000000           0.258  2011-12-15   \n",
       "1  MAC000126  2011-12-15 11:00:00.0000000           0.091  2011-12-15   \n",
       "2  MAC000126  2011-12-15 11:30:00.0000000           0.043  2011-12-15   \n",
       "3  MAC000126  2011-12-15 12:00:00.0000000           0.109  2011-12-15   \n",
       "4  MAC000126  2011-12-15 12:30:00.0000000           0.262  2011-12-15   \n",
       "\n",
       "      month  day_of_month      time   weekday  day_seconds  energy  \\\n",
       "0  December            15  10:30:00  Thursday      37800.0   0.258   \n",
       "1  December            15  11:00:00  Thursday      39600.0   0.091   \n",
       "2  December            15  11:30:00  Thursday      41400.0   0.043   \n",
       "3  December            15  12:00:00  Thursday      43200.0   0.109   \n",
       "4  December            15  12:30:00  Thursday      45000.0   0.262   \n",
       "\n",
       "   cumulative_sum  \n",
       "0           0.258  \n",
       "1           0.349  \n",
       "2           0.392  \n",
       "3           0.501  \n",
       "4           0.763  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488e15e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaex\n",
      "  Downloading vaex-4.17.0-py3-none-any.whl (4.8 kB)\n",
      "Collecting vaex-hdf5<0.15,>=0.13.0\n",
      "  Downloading vaex_hdf5-0.14.1-py3-none-any.whl (16 kB)\n",
      "Collecting vaex-ml<0.19,>=0.18.3\n",
      "  Downloading vaex_ml-0.18.3-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 4.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting vaex-viz<0.6,>=0.5.4\n",
      "  Downloading vaex_viz-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting vaex-astro<0.10,>=0.9.3\n",
      "  Downloading vaex_astro-0.9.3-py3-none-any.whl (20 kB)\n",
      "Collecting vaex-core~=4.17.1\n",
      "  Downloading vaex_core-4.17.1-cp38-cp38-macosx_10_9_x86_64.whl (5.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.2 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting vaex-jupyter<0.9,>=0.8.2\n",
      "  Downloading vaex_jupyter-0.8.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting vaex-server~=0.9.0\n",
      "  Downloading vaex_server-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: astropy in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-astro<0.10,>=0.9.3->vaex) (4.2.1)\n",
      "Collecting pyarrow>=5.0.0\n",
      "  Downloading pyarrow-14.0.1-cp38-cp38-macosx_10_14_x86_64.whl (26.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.8 MB 903 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio>=1.3.3 in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (1.5.1)\n",
      "Collecting tabulate>=0.8.3\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (2.25.1)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (3.0.12)\n",
      "Collecting progressbar2\n",
      "  Downloading progressbar2-4.2.0-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (1.2.4)\n",
      "Requirement already satisfied: pyyaml in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (5.4.1)\n",
      "Requirement already satisfied: cloudpickle in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (1.6.0)\n",
      "Requirement already satisfied: dask!=2022.4.0 in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (2021.4.0)\n",
      "Collecting pydantic>=1.8.0\n",
      "  Downloading pydantic-2.5.1-py3-none-any.whl (381 kB)\n",
      "\u001b[K     |████████████████████████████████| 381 kB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (1.20.1)\n",
      "Requirement already satisfied: future>=0.15.2 in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (0.18.2)\n",
      "Collecting frozendict!=2.2.0\n",
      "  Downloading frozendict-2.3.8-cp38-cp38-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting aplus\n",
      "  Downloading aplus-0.11.0.tar.gz (3.7 kB)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-core~=4.17.1->vaex) (1.15.0)\n",
      "Collecting rich\n",
      "  Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[K     |████████████████████████████████| 240 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blake3\n",
      "  Downloading blake3-0.3.3-cp38-cp38-macosx_10_7_x86_64.whl (357 kB)\n",
      "\u001b[K     |████████████████████████████████| 357 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: partd>=0.3.10 in ./opt/anaconda3/lib/python3.8/site-packages (from dask!=2022.4.0->vaex-core~=4.17.1->vaex) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in ./opt/anaconda3/lib/python3.8/site-packages (from dask!=2022.4.0->vaex-core~=4.17.1->vaex) (0.9.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in ./opt/anaconda3/lib/python3.8/site-packages (from dask!=2022.4.0->vaex-core~=4.17.1->vaex) (0.11.1)\n",
      "Requirement already satisfied: locket in ./opt/anaconda3/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg (from partd>=0.3.10->dask!=2022.4.0->vaex-core~=4.17.1->vaex) (0.2.1)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.14.3\n",
      "  Downloading pydantic_core-2.14.3-cp38-cp38-macosx_10_7_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9 in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-hdf5<0.15,>=0.13.0->vaex) (2.10.0)\n",
      "Collecting ipyleaflet\n",
      "  Downloading ipyleaflet-0.17.4-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipympl\n",
      "  Downloading ipympl-0.9.3-py2.py3-none-any.whl (511 kB)\n",
      "\u001b[K     |████████████████████████████████| 511 kB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bqplot>=0.10.1\n",
      "  Downloading bqplot-0.12.42-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xarray\n",
      "  Downloading xarray-2023.1.0-py3-none-any.whl (973 kB)\n",
      "\u001b[K     |████████████████████████████████| 973 kB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipyvolume>=0.4\n",
      "  Downloading ipyvolume-0.6.3-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipyvuetify<2,>=1.2.2\n",
      "  Downloading ipyvuetify-1.8.10-py2.py3-none-any.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets<9,>=7.5.0 in ./opt/anaconda3/lib/python3.8/site-packages (from bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (7.6.3)\n",
      "Collecting traittypes>=0.0.6\n",
      "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: traitlets>=4.3.0 in ./opt/anaconda3/lib/python3.8/site-packages (from bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (5.0.5)\n",
      "Requirement already satisfied: Pillow in ./opt/anaconda3/lib/python3.8/site-packages (from ipyvolume>=0.4->vaex-jupyter<0.9,>=0.8.2->vaex) (8.2.0)\n",
      "Collecting ipyvue>=1.7.0\n",
      "  Downloading ipyvue-1.10.1-py2.py3-none-any.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pythreejs>=2.4.0\n",
      "  Downloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in ./opt/anaconda3/lib/python3.8/site-packages (from ipyvolume>=0.4->vaex-jupyter<0.9,>=0.8.2->vaex) (3.3.4)\n",
      "Collecting ipywebrtc\n",
      "  Downloading ipywebrtc-0.6.0-py2.py3-none-any.whl (260 kB)\n",
      "\u001b[K     |████████████████████████████████| 260 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyterlab-widgets>=1.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (1.0.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./opt/anaconda3/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (5.3.4)\n",
      "Requirement already satisfied: ipython>=4.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (7.22.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./opt/anaconda3/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./opt/anaconda3/lib/python3.8/site-packages (from ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (3.5.1)\n",
      "Requirement already satisfied: appnope in ./opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client in ./opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in ./opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (52.0.0.post20210125)\n",
      "Requirement already satisfied: decorator in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (5.0.6)\n",
      "Requirement already satisfied: pexpect>4.3 in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.17.2)\n",
      "Requirement already satisfied: backcall in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (3.0.17)\n",
      "Requirement already satisfied: pygments in ./opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (2.8.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in ./opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.7.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in ./opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in ./opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (4.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in ./opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.17.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./opt/anaconda3/lib/python3.8/site-packages (from pandas->vaex-core~=4.17.1->vaex) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./opt/anaconda3/lib/python3.8/site-packages (from pandas->vaex-core~=4.17.1->vaex) (2021.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./opt/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.2.5)\n",
      "Collecting ipydatawidgets>=1.1.1\n",
      "  Downloading ipydatawidgets-4.3.5-py2.py3-none-any.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-ml<0.19,>=0.18.3->vaex) (2.11.3)\n",
      "Requirement already satisfied: numba in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-ml<0.19,>=0.18.3->vaex) (0.53.1)\n",
      "Requirement already satisfied: cachetools in ./opt/anaconda3/lib/python3.8/site-packages (from vaex-server~=0.9.0->vaex) (5.2.0)\n",
      "Collecting uvicorn[standard]\n",
      "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
      "\u001b[K     |████████████████████████████████| 92 kB 4.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib->ipyvolume>=0.4->vaex-jupyter<0.9,>=0.8.2->vaex) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib->ipyvolume>=0.4->vaex-jupyter<0.9,>=0.8.2->vaex) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib->ipyvolume>=0.4->vaex-jupyter<0.9,>=0.8.2->vaex) (2.4.7)\n",
      "Requirement already satisfied: notebook>=4.4.1 in ./opt/anaconda3/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (6.3.0)\n",
      "Requirement already satisfied: pyzmq>=17 in ./opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (20.0.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in ./opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.9.4)\n",
      "Requirement already satisfied: prometheus-client in ./opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.10.1)\n",
      "Requirement already satisfied: argon2-cffi in ./opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (20.1.0)\n",
      "Requirement already satisfied: nbconvert in ./opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (6.0.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (1.14.5)\n",
      "Requirement already satisfied: pycparser in ./opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (2.20)\n",
      "Requirement already satisfied: pyerfa in ./opt/anaconda3/lib/python3.8/site-packages (from astropy->vaex-astro<0.10,>=0.9.3->vaex) (1.7.3)\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 6.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting anyio<4.0.0,>=3.7.1\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 6.7 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in ./opt/anaconda3/lib/python3.8/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->vaex-server~=0.9.0->vaex) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./opt/anaconda3/lib/python3.8/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->vaex-server~=0.9.0->vaex) (2.10)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting branca>=0.5.0\n",
      "  Downloading branca-0.7.0-py3-none-any.whl (25 kB)\n",
      "Collecting xyzservices>=2021.8.1\n",
      "  Downloading xyzservices-2023.10.1-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 5.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.7.4-cp38-cp38-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.4 MB 6.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-macosx_10_9_x86_64.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.8/site-packages (from matplotlib->ipyvolume>=0.4->vaex-jupyter<0.9,>=0.8.2->vaex) (20.9)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.45.0-cp38-cp38-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->ipyvolume>=0.4->vaex-jupyter<0.9,>=0.8.2->vaex) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./opt/anaconda3/lib/python3.8/site-packages (from jinja2->vaex-ml<0.19,>=0.18.3->vaex) (1.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.1.2)\n",
      "Requirement already satisfied: testpath in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.5.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (1.4.3)\n",
      "Requirement already satisfied: bleach in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.8.4)\n",
      "Requirement already satisfied: async-generator in ./opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (1.10)\n",
      "Requirement already satisfied: webencodings in ./opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<9,>=7.5.0->bqplot>=0.10.1->vaex-jupyter<0.9,>=0.8.2->vaex) (0.5.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in ./opt/anaconda3/lib/python3.8/site-packages (from numba->vaex-ml<0.19,>=0.18.3->vaex) (0.36.0)\n",
      "Collecting python-utils>=3.0.0\n",
      "  Downloading python_utils-3.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->vaex-core~=4.17.1->vaex) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->vaex-core~=4.17.1->vaex) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->vaex-core~=4.17.1->vaex) (1.26.4)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 7.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pygments\n",
      "  Downloading pygments-2.17.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in ./opt/anaconda3/lib/python3.8/site-packages (from uvicorn[standard]->vaex-server~=0.9.0->vaex) (7.1.2)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-12.0-cp38-cp38-macosx_10_9_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp38-cp38-macosx_10_9_x86_64.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.21.0-cp38-cp38-macosx_10_7_x86_64.whl (429 kB)\n",
      "\u001b[K     |████████████████████████████████| 429 kB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.19.0-cp38-cp38-macosx_10_9_x86_64.whl (803 kB)\n",
      "\u001b[K     |████████████████████████████████| 803 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=20.0\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 9.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[K     |████████████████████████████████| 341 kB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.16\n",
      "  Downloading numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.8 MB 8.4 MB/s eta 0:00:01     |████████████████████████▍       | 15.0 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: aplus\n",
      "  Building wheel for aplus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aplus: filename=aplus-0.11.0-py3-none-any.whl size=4411 sha256=5045cbb792abc60e67b0b06f6fe0d6d30a3b092e0d39484965700b0c8241e2b7\n",
      "  Stored in directory: /Users/ishanyash17/Library/Caches/pip/wheels/de/93/23/3db69e1003030a764c9827dc02137119ec5e6e439afd64eebb\n",
      "Successfully built aplus\n",
      "Installing collected packages: python-dateutil, pygments, packaging, typing-extensions, mdurl, tzdata, traittypes, python-utils, pydantic-core, numpy, markdown-it-py, exceptiongroup, annotated-types, tabulate, rich, pydantic, pyarrow, progressbar2, pandas, ipyvue, ipydatawidgets, importlib-resources, h11, frozendict, fonttools, contourpy, blake3, aplus, anyio, xyzservices, websockets, watchfiles, vaex-core, uvloop, uvicorn, starlette, pythreejs, python-dotenv, matplotlib, ipywebrtc, ipyvuetify, httptools, branca, bqplot, xarray, vaex-viz, ipyvolume, ipympl, ipyleaflet, fastapi, vaex-server, vaex-ml, vaex-jupyter, vaex-hdf5, vaex-astro, vaex\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.8.1\n",
      "    Uninstalling Pygments-2.8.1:\n",
      "      Successfully uninstalled Pygments-2.8.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.4\n",
      "    Uninstalling pandas-1.2.4:\n",
      "      Successfully uninstalled pandas-1.2.4\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 2.2.0\n",
      "    Uninstalling anyio-2.2.0:\n",
      "      Successfully uninstalled anyio-2.2.0\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.4\n",
      "    Uninstalling matplotlib-3.3.4:\n",
      "      Successfully uninstalled matplotlib-3.3.4\n",
      "  Attempting uninstall: branca\n",
      "    Found existing installation: branca 0.4.2\n",
      "    Uninstalling branca-0.4.2:\n",
      "      Successfully uninstalled branca-0.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.2.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "scipy 1.6.2 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.4 which is incompatible.\u001b[0m\n",
      "Successfully installed annotated-types-0.6.0 anyio-3.7.1 aplus-0.11.0 blake3-0.3.3 bqplot-0.12.42 branca-0.7.0 contourpy-1.1.1 exceptiongroup-1.2.0 fastapi-0.104.1 fonttools-4.45.0 frozendict-2.3.8 h11-0.14.0 httptools-0.6.1 importlib-resources-6.1.1 ipydatawidgets-4.3.5 ipyleaflet-0.17.4 ipympl-0.9.3 ipyvolume-0.6.3 ipyvue-1.10.1 ipyvuetify-1.8.10 ipywebrtc-0.6.0 markdown-it-py-3.0.0 matplotlib-3.7.4 mdurl-0.1.2 numpy-1.24.4 packaging-23.2 pandas-2.0.3 progressbar2-4.2.0 pyarrow-14.0.1 pydantic-2.5.1 pydantic-core-2.14.3 pygments-2.17.1 python-dateutil-2.8.2 python-dotenv-1.0.0 python-utils-3.8.1 pythreejs-2.4.2 rich-13.7.0 starlette-0.27.0 tabulate-0.9.0 traittypes-0.2.1 typing-extensions-4.8.0 tzdata-2023.3 uvicorn-0.24.0.post1 uvloop-0.19.0 vaex-4.17.0 vaex-astro-0.9.3 vaex-core-4.17.1 vaex-hdf5-0.14.1 vaex-jupyter-0.8.2 vaex-ml-0.18.3 vaex-server-0.9.0 vaex-viz-0.5.4 watchfiles-0.21.0 websockets-12.0 xarray-2023.1.0 xyzservices-2023.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3cec3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming all files are in the same directory\n",
    "folder_path = '/Users/ishanyash17/Downloads/preprocessed_block_ds'\n",
    "all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Function to extract block name from file name\n",
    "def get_block_name(file_path):\n",
    "    return os.path.basename(file_path).split('_')[2]\n",
    "\n",
    "# Read files and store in a list\n",
    "df_list = [pd.read_csv(file).assign(block_name=get_block_name(file)) for file in all_files]\n",
    "\n",
    "# Concatenate all datasets with an additional 'block_name' column\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Save the merged dataset\n",
    "df_all.to_csv('/Users/ishanyash17/Downloads/merged_hh_block035_dataset1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff04fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('/Users/ishanyash17/Downloads/merged_hh_block035_dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e8b3290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>tstp</th>\n",
       "      <th>energy(kWh/hh)</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_seconds</th>\n",
       "      <th>energy</th>\n",
       "      <th>cumulative_sum</th>\n",
       "      <th>block_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 10:30:00.0000000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.258</td>\n",
       "      <td>Block28.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:00:00.0000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.349</td>\n",
       "      <td>Block28.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:30:00.0000000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>41400.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.392</td>\n",
       "      <td>Block28.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:00:00.0000000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.501</td>\n",
       "      <td>Block28.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:30:00.0000000</td>\n",
       "      <td>0.262</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.763</td>\n",
       "      <td>Block28.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid                         tstp  energy(kWh/hh)        date  \\\n",
       "0  MAC000126  2011-12-15 10:30:00.0000000           0.258  2011-12-15   \n",
       "1  MAC000126  2011-12-15 11:00:00.0000000           0.091  2011-12-15   \n",
       "2  MAC000126  2011-12-15 11:30:00.0000000           0.043  2011-12-15   \n",
       "3  MAC000126  2011-12-15 12:00:00.0000000           0.109  2011-12-15   \n",
       "4  MAC000126  2011-12-15 12:30:00.0000000           0.262  2011-12-15   \n",
       "\n",
       "      month  day_of_month      time   weekday  day_seconds  energy  \\\n",
       "0  December            15  10:30:00  Thursday      37800.0   0.258   \n",
       "1  December            15  11:00:00  Thursday      39600.0   0.091   \n",
       "2  December            15  11:30:00  Thursday      41400.0   0.043   \n",
       "3  December            15  12:00:00  Thursday      43200.0   0.109   \n",
       "4  December            15  12:30:00  Thursday      45000.0   0.262   \n",
       "\n",
       "   cumulative_sum   block_name  \n",
       "0           0.258  Block28.csv  \n",
       "1           0.349  Block28.csv  \n",
       "2           0.392  Block28.csv  \n",
       "3           0.501  Block28.csv  \n",
       "4           0.763  Block28.csv  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fd4d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '.csv' from the 'block_name' column\n",
    "df_merged['block_name'] = df_merged['block_name'].str.replace('.csv', '', regex=False)\n",
    "\n",
    "# Save the modified DataFrame back to CSV if needed\n",
    "df_merged.to_csv('/Users/ishanyash17/Downloads/merged_hh_block035_dataset_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff85bcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>tstp</th>\n",
       "      <th>energy(kWh/hh)</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_seconds</th>\n",
       "      <th>energy</th>\n",
       "      <th>cumulative_sum</th>\n",
       "      <th>block_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 10:30:00.0000000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.258</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:00:00.0000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.349</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:30:00.0000000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>41400.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.392</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:00:00.0000000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.501</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:30:00.0000000</td>\n",
       "      <td>0.262</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.763</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid                         tstp  energy(kWh/hh)        date  \\\n",
       "0  MAC000126  2011-12-15 10:30:00.0000000           0.258  2011-12-15   \n",
       "1  MAC000126  2011-12-15 11:00:00.0000000           0.091  2011-12-15   \n",
       "2  MAC000126  2011-12-15 11:30:00.0000000           0.043  2011-12-15   \n",
       "3  MAC000126  2011-12-15 12:00:00.0000000           0.109  2011-12-15   \n",
       "4  MAC000126  2011-12-15 12:30:00.0000000           0.262  2011-12-15   \n",
       "\n",
       "      month  day_of_month      time   weekday  day_seconds  energy  \\\n",
       "0  December            15  10:30:00  Thursday      37800.0   0.258   \n",
       "1  December            15  11:00:00  Thursday      39600.0   0.091   \n",
       "2  December            15  11:30:00  Thursday      41400.0   0.043   \n",
       "3  December            15  12:00:00  Thursday      43200.0   0.109   \n",
       "4  December            15  12:30:00  Thursday      45000.0   0.262   \n",
       "\n",
       "   cumulative_sum block_name  \n",
       "0           0.258    Block28  \n",
       "1           0.349    Block28  \n",
       "2           0.392    Block28  \n",
       "3           0.501    Block28  \n",
       "4           0.763    Block28  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf284cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_merged is your DataFrame after reading from CSV\n",
    "# df_merged = pd.read_csv('path_to_your_csv_file')\n",
    "\n",
    "# Group by 'block_name' and calculate the total energy used per block\n",
    "block_energy_totals = df_merged.groupby('block_name')['energy'].sum().reset_index()\n",
    "\n",
    "# Sort the blocks by total energy used in descending order and get the top 32 blocks\n",
    "top_blocks = block_energy_totals.sort_values(by='energy', ascending=False).head(32)\n",
    "\n",
    "# Filter the original DataFrame to keep only the rows from the top 32 blocks\n",
    "df_filtered = df_merged[df_merged['block_name'].isin(top_blocks['block_name'])]\n",
    "\n",
    "# Now df_filtered contains only the data for the top 32 blocks by energy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f62d9bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>tstp</th>\n",
       "      <th>energy(kWh/hh)</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_seconds</th>\n",
       "      <th>energy</th>\n",
       "      <th>cumulative_sum</th>\n",
       "      <th>block_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 10:30:00.0000000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.258</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:00:00.0000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.349</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:30:00.0000000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>41400.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.392</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:00:00.0000000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.501</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:30:00.0000000</td>\n",
       "      <td>0.262</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.763</td>\n",
       "      <td>Block28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid                         tstp  energy(kWh/hh)        date  \\\n",
       "0  MAC000126  2011-12-15 10:30:00.0000000           0.258  2011-12-15   \n",
       "1  MAC000126  2011-12-15 11:00:00.0000000           0.091  2011-12-15   \n",
       "2  MAC000126  2011-12-15 11:30:00.0000000           0.043  2011-12-15   \n",
       "3  MAC000126  2011-12-15 12:00:00.0000000           0.109  2011-12-15   \n",
       "4  MAC000126  2011-12-15 12:30:00.0000000           0.262  2011-12-15   \n",
       "\n",
       "      month  day_of_month      time   weekday  day_seconds  energy  \\\n",
       "0  December            15  10:30:00  Thursday      37800.0   0.258   \n",
       "1  December            15  11:00:00  Thursday      39600.0   0.091   \n",
       "2  December            15  11:30:00  Thursday      41400.0   0.043   \n",
       "3  December            15  12:00:00  Thursday      43200.0   0.109   \n",
       "4  December            15  12:30:00  Thursday      45000.0   0.262   \n",
       "\n",
       "   cumulative_sum block_name  \n",
       "0           0.258    Block28  \n",
       "1           0.349    Block28  \n",
       "2           0.392    Block28  \n",
       "3           0.501    Block28  \n",
       "4           0.763    Block28  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "808856b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered['block_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fda8396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-e7bd4fd3b7a2>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['borough_name'] = df_filtered['block_name'].map(block_to_borough)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Block28', 'Block14', 'Block15', 'Block29', 'Block17', 'Block16',\n",
       "       'Block12', 'Block13', 'Block11', 'Block8', 'Block9', 'Block10',\n",
       "       'Block35', 'Block4', 'Block5', 'Block20', 'Block34', 'Block22',\n",
       "       'Block7', 'Block6', 'Block27', 'Block33', 'Block2', 'Block3',\n",
       "       'Block30', 'Block24', 'Block18', 'Block1', 'Block0', 'Block19',\n",
       "       'Block25', 'Block31'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# List of London borough names\n",
    "boroughs = [\n",
    "    \"Barking and Dagenham\", \"Barnet\", \"Bexley\", \"Brent\", \"Bromley\", \"Camden\",\n",
    "    \"Croydon\", \"Ealing\", \"Enfield\", \"Greenwich\", \"Hackney\",\n",
    "    \"Hammersmith and Fulham\", \"Haringey\", \"Harrow\", \"Havering\", \"Hillingdon\",\n",
    "    \"Hounslow\", \"Islington\", \"Kensington and Chelsea\", \"Kingston upon Thames\",\n",
    "    \"Lambeth\", \"Lewisham\", \"Merton\", \"Newham\", \"Redbridge\",\n",
    "    \"Richmond upon Thames\", \"Southwark\", \"Sutton\", \"Tower Hamlets\",\n",
    "    \"Waltham Forest\", \"Wandsworth\", \"Westminster\"\n",
    "]\n",
    "\n",
    "# Ensure the random assignment is reproducible\n",
    "random.seed(0)\n",
    "\n",
    "# Shuffle the boroughs list\n",
    "random.shuffle(boroughs)\n",
    "\n",
    "# Map the shuffled borough names to the blocks\n",
    "block_to_borough = dict(zip(df_filtered['block_name'].unique(), boroughs))\n",
    "\n",
    "# Assign the borough names to each row in the filtered DataFrame\n",
    "df_filtered['borough_name'] = df_filtered['block_name'].map(block_to_borough)\n",
    "\n",
    "# Now df_filtered contains a new column 'borough_name' with the assigned borough names\n",
    "df_filtered['block_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33143c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>tstp</th>\n",
       "      <th>energy(kWh/hh)</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day_seconds</th>\n",
       "      <th>energy</th>\n",
       "      <th>cumulative_sum</th>\n",
       "      <th>block_name</th>\n",
       "      <th>borough_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 10:30:00.0000000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.258</td>\n",
       "      <td>Block28</td>\n",
       "      <td>Brent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:00:00.0000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.349</td>\n",
       "      <td>Block28</td>\n",
       "      <td>Brent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 11:30:00.0000000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>41400.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.392</td>\n",
       "      <td>Block28</td>\n",
       "      <td>Brent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:00:00.0000000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.501</td>\n",
       "      <td>Block28</td>\n",
       "      <td>Brent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC000126</td>\n",
       "      <td>2011-12-15 12:30:00.0000000</td>\n",
       "      <td>0.262</td>\n",
       "      <td>2011-12-15</td>\n",
       "      <td>December</td>\n",
       "      <td>15</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.763</td>\n",
       "      <td>Block28</td>\n",
       "      <td>Brent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid                         tstp  energy(kWh/hh)        date  \\\n",
       "0  MAC000126  2011-12-15 10:30:00.0000000           0.258  2011-12-15   \n",
       "1  MAC000126  2011-12-15 11:00:00.0000000           0.091  2011-12-15   \n",
       "2  MAC000126  2011-12-15 11:30:00.0000000           0.043  2011-12-15   \n",
       "3  MAC000126  2011-12-15 12:00:00.0000000           0.109  2011-12-15   \n",
       "4  MAC000126  2011-12-15 12:30:00.0000000           0.262  2011-12-15   \n",
       "\n",
       "      month  day_of_month      time   weekday  day_seconds  energy  \\\n",
       "0  December            15  10:30:00  Thursday      37800.0   0.258   \n",
       "1  December            15  11:00:00  Thursday      39600.0   0.091   \n",
       "2  December            15  11:30:00  Thursday      41400.0   0.043   \n",
       "3  December            15  12:00:00  Thursday      43200.0   0.109   \n",
       "4  December            15  12:30:00  Thursday      45000.0   0.262   \n",
       "\n",
       "   cumulative_sum block_name borough_name  \n",
       "0           0.258    Block28        Brent  \n",
       "1           0.349    Block28        Brent  \n",
       "2           0.392    Block28        Brent  \n",
       "3           0.501    Block28        Brent  \n",
       "4           0.763    Block28        Brent  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc2a8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough = df_filtered.drop(['block_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57eabc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Brent', 'Ealing', 'Waltham Forest', 'Lambeth',\n",
       "       'Kingston upon Thames', 'Camden', 'Barking and Dagenham',\n",
       "       'Hackney', 'Havering', 'Southwark', 'Islington', 'Lewisham',\n",
       "       'Sutton', 'Newham', 'Bexley', 'Merton', 'Bromley',\n",
       "       'Richmond upon Thames', 'Croydon', 'Kensington and Chelsea',\n",
       "       'Hammersmith and Fulham', 'Wandsworth', 'Greenwich', 'Haringey',\n",
       "       'Hillingdon', 'Hounslow', 'Enfield', 'Barnet', 'Harrow',\n",
       "       'Tower Hamlets', 'Westminster', 'Redbridge'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_borough.head()\n",
    "df_borough['borough_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecb1ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough.to_csv(r'/Users/ishanyash17/Downloads/London_Borough_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1ca4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "chunk_size = 1000000  # Adjust based on your system's memory capacity\n",
    "samples_per_borough = 10  # Or any number that gives you a small enough file\n",
    "folder_path = '/Users/ishanyash17/Downloads/London_Borough_ds.csv'\n",
    "output_path = '/Users/ishanyash17/Downloads/London_Borough_ds_snippet1.csv'\n",
    "\n",
    "# Initialize a DataFrame to hold the final stratified sample\n",
    "df_stratified_sample = pd.DataFrame()\n",
    "\n",
    "# Read the large CSV file in chunks\n",
    "for chunk in pd.read_csv(folder_path, chunksize=chunk_size):\n",
    "    # Group by 'borough_name' and apply the sampling\n",
    "    chunk_sample = chunk.groupby('borough_name', group_keys=False).apply(lambda x: x.sample(min(len(x), samples_per_borough)))\n",
    "    df_stratified_sample = pd.concat([df_stratified_sample, chunk_sample])\n",
    "\n",
    "# Because we're sampling from each chunk, we might get more samples than we want, so we resample\n",
    "df_stratified_sample = df_stratified_sample.groupby('borough_name', group_keys=False).apply(lambda x: x.sample(min(len(x), samples_per_borough)))\n",
    "\n",
    "# Save the stratified sample to a new CSV file\n",
    "df_stratified_sample.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac5a7dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ce90abe7104d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tstp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tstp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2013\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf_2014\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Reset the index of the final DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             new_data = concatenate_managers(\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mfastpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mfastpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, copy)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mtarget_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_find_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkinds\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"u\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# GH#39817 cast to object instead of casting bools to numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the path to your dataset and the output file\n",
    "input_file_path = '/Users/ishanyash17/Downloads/London_Borough_ds.csv'\n",
    "output_file_path = '/Users/ishanyash17/Downloads/SMLondon_Borough_2013.csv'\n",
    "\n",
    "# Initialize an empty DataFrame to hold the filtered data\n",
    "df_2014 = pd.DataFrame()\n",
    "\n",
    "# Read the dataset in chunks and filter by year 2014\n",
    "chunk_size = 100000  # Adjust this size based on your system's capabilities\n",
    "for chunk in pd.read_csv(input_file_path, chunksize=chunk_size, parse_dates=['tstp']):\n",
    "    chunk = chunk[chunk['tstp'].dt.year == 2013]\n",
    "    df_2014 = pd.concat([df_2014, chunk])\n",
    "\n",
    "# Reset the index of the final DataFrame\n",
    "df_2014.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the filtered dataset to a new CSV file\n",
    "df_2014.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822791e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-1544a03f0b1a>:1: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_postcodes = pd.read_csv('/Users/ishanyash17/Downloads/London postcodes.csv')\n"
     ]
    }
   ],
   "source": [
    "df_postcodes = pd.read_csv('/Users/ishanyash17/Downloads/London postcodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a341e67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode</th>\n",
       "      <th>In Use?</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "      <th>Grid Ref</th>\n",
       "      <th>County</th>\n",
       "      <th>District</th>\n",
       "      <th>Ward</th>\n",
       "      <th>...</th>\n",
       "      <th>Travel To Work Area</th>\n",
       "      <th>ITL level 2</th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>UPRNs</th>\n",
       "      <th>Distance to sea</th>\n",
       "      <th>LSOA21 Code</th>\n",
       "      <th>Lower layer super output area 2021</th>\n",
       "      <th>MSOA21 Code</th>\n",
       "      <th>Middle layer super output area 2021</th>\n",
       "      <th>Census output area 2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR1 1AA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.401546</td>\n",
       "      <td>0.015415</td>\n",
       "      <td>540291</td>\n",
       "      <td>168873</td>\n",
       "      <td>TQ402688</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>Bromley Town</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - South</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>10070014435,10070014436,10070014437,1007001443...</td>\n",
       "      <td>28.0730</td>\n",
       "      <td>E01034386</td>\n",
       "      <td>Bromley 018G</td>\n",
       "      <td>E02000144</td>\n",
       "      <td>Bromley South</td>\n",
       "      <td>E00182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BR1 1AB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.406333</td>\n",
       "      <td>0.015208</td>\n",
       "      <td>540262</td>\n",
       "      <td>169405</td>\n",
       "      <td>TQ402694</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>Bromley Town</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - South</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>10070008860,10070008861,10070008862,1007000886...</td>\n",
       "      <td>27.9776</td>\n",
       "      <td>E01000676</td>\n",
       "      <td>Bromley 008B</td>\n",
       "      <td>E02000134</td>\n",
       "      <td>Bromley North &amp; Sundridge</td>\n",
       "      <td>E00003255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BR1 1AD</td>\n",
       "      <td>No</td>\n",
       "      <td>51.400057</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>540386</td>\n",
       "      <td>168710</td>\n",
       "      <td>TQ403687</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>Bromley Town</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - South</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0211</td>\n",
       "      <td>E01034386</td>\n",
       "      <td>Bromley 018G</td>\n",
       "      <td>E02000144</td>\n",
       "      <td>Bromley South</td>\n",
       "      <td>E00182639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR1 1AE</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.404543</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>540197</td>\n",
       "      <td>169204</td>\n",
       "      <td>TQ401692</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>Bromley Town</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - South</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>10003640209,10070000614,10070002658,1007000265...</td>\n",
       "      <td>28.0861</td>\n",
       "      <td>E01000677</td>\n",
       "      <td>Bromley 018C</td>\n",
       "      <td>E02000144</td>\n",
       "      <td>Bromley South</td>\n",
       "      <td>E00003266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BR1 1AF</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.401392</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>540259</td>\n",
       "      <td>168855</td>\n",
       "      <td>TQ402688</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>Bromley Town</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - South</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>10070014484,10070014485,10070014486,1007001448...</td>\n",
       "      <td>28.1083</td>\n",
       "      <td>E01034386</td>\n",
       "      <td>Bromley 018G</td>\n",
       "      <td>E02000144</td>\n",
       "      <td>Bromley South</td>\n",
       "      <td>E00182600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postcode In Use?   Latitude  Longitude  Easting  Northing  Grid Ref  \\\n",
       "0  BR1 1AA     Yes  51.401546   0.015415   540291    168873  TQ402688   \n",
       "1  BR1 1AB     Yes  51.406333   0.015208   540262    169405  TQ402694   \n",
       "2  BR1 1AD      No  51.400057   0.016715   540386    168710  TQ403687   \n",
       "3  BR1 1AE     Yes  51.404543   0.014195   540197    169204  TQ401692   \n",
       "4  BR1 1AF     Yes  51.401392   0.014948   540259    168855  TQ402688   \n",
       "\n",
       "           County District          Ward  ... Travel To Work Area  \\\n",
       "0  Greater London  Bromley  Bromley Town  ...              London   \n",
       "1  Greater London  Bromley  Bromley Town  ...              London   \n",
       "2  Greater London  Bromley  Bromley Town  ...              London   \n",
       "3  Greater London  Bromley  Bromley Town  ...              London   \n",
       "4  Greater London  Bromley  Bromley Town  ...              London   \n",
       "\n",
       "            ITL level 2 ITL level 3  \\\n",
       "0  Outer London - South     Bromley   \n",
       "1  Outer London - South     Bromley   \n",
       "2  Outer London - South     Bromley   \n",
       "3  Outer London - South     Bromley   \n",
       "4  Outer London - South     Bromley   \n",
       "\n",
       "                                               UPRNs Distance to sea  \\\n",
       "0  10070014435,10070014436,10070014437,1007001443...         28.0730   \n",
       "1  10070008860,10070008861,10070008862,1007000886...         27.9776   \n",
       "2                                                NaN         28.0211   \n",
       "3  10003640209,10070000614,10070002658,1007000265...         28.0861   \n",
       "4  10070014484,10070014485,10070014486,1007001448...         28.1083   \n",
       "\n",
       "  LSOA21 Code Lower layer super output area 2021 MSOA21 Code  \\\n",
       "0   E01034386                       Bromley 018G   E02000144   \n",
       "1   E01000676                       Bromley 008B   E02000134   \n",
       "2   E01034386                       Bromley 018G   E02000144   \n",
       "3   E01000677                       Bromley 018C   E02000144   \n",
       "4   E01034386                       Bromley 018G   E02000144   \n",
       "\n",
       "   Middle layer super output area 2021  Census output area 2021  \n",
       "0                        Bromley South                E00182600  \n",
       "1            Bromley North & Sundridge                E00003255  \n",
       "2                        Bromley South                E00182639  \n",
       "3                        Bromley South                E00003266  \n",
       "4                        Bromley South                E00182600  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_postcodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a986bcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_postcodes['District'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1073c076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-c09724821605>:11: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(folder_path, chunksize=chunk_size):\n"
     ]
    }
   ],
   "source": [
    "# Snippet of Postcode Dataset\n",
    "chunk_size = 1000000  # Adjust based on your system's memory capacity\n",
    "samples_per_district = 10  # Or any number that gives you a small enough file\n",
    "folder_path = '/Users/ishanyash17/Downloads/London postcodes.csv'\n",
    "output_path = '/Users/ishanyash17/Downloads/London postcodes_snippet.csv'\n",
    "\n",
    "# Initialize a DataFrame to hold the final stratified sample\n",
    "df_stratified_postcode = pd.DataFrame()\n",
    "\n",
    "# Read the large CSV file in chunks\n",
    "for chunk in pd.read_csv(folder_path, chunksize=chunk_size):\n",
    "    # Group by 'borough_name' and apply the sampling\n",
    "    chunk_sample = chunk.groupby('District', group_keys=False).apply(lambda x: x.sample(min(len(x), samples_per_district)))\n",
    "    df_stratified_postcode = pd.concat([df_stratified_postcode, chunk_sample])\n",
    "\n",
    "# Because we're sampling from each chunk, we might get more samples than we want, so we resample\n",
    "df_stratified_postcode = df_stratified_postcode.groupby('District', group_keys=False).apply(lambda x: x.sample(min(len(x), samples_per_district)))\n",
    "\n",
    "# Save the stratified sample to a new CSV file\n",
    "df_stratified_postcode.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394969a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode</th>\n",
       "      <th>In Use?</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "      <th>Grid Ref</th>\n",
       "      <th>County</th>\n",
       "      <th>District</th>\n",
       "      <th>Ward</th>\n",
       "      <th>...</th>\n",
       "      <th>Travel To Work Area</th>\n",
       "      <th>ITL level 2</th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>UPRNs</th>\n",
       "      <th>Distance to sea</th>\n",
       "      <th>LSOA21 Code</th>\n",
       "      <th>Lower layer super output area 2021</th>\n",
       "      <th>MSOA21 Code</th>\n",
       "      <th>Middle layer super output area 2021</th>\n",
       "      <th>Census output area 2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175870</th>\n",
       "      <td>RM8 3BA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.555856</td>\n",
       "      <td>0.140103</td>\n",
       "      <td>548462</td>\n",
       "      <td>186278</td>\n",
       "      <td>TQ484862</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>Valence</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - East and North East</td>\n",
       "      <td>Barking &amp; Dagenham and Havering</td>\n",
       "      <td>100031158,100031159,100031160,100031161,100031...</td>\n",
       "      <td>21.8478</td>\n",
       "      <td>E01000102</td>\n",
       "      <td>Barking and Dagenham 007G</td>\n",
       "      <td>E02000008</td>\n",
       "      <td>Becontree East</td>\n",
       "      <td>E00000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175757</th>\n",
       "      <td>RM8 2RR</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.552265</td>\n",
       "      <td>0.117937</td>\n",
       "      <td>546937</td>\n",
       "      <td>185834</td>\n",
       "      <td>TQ469858</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>Becontree</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - East and North East</td>\n",
       "      <td>Barking &amp; Dagenham and Havering</td>\n",
       "      <td>100005702,100005704,100005706,100005707,100005...</td>\n",
       "      <td>22.9885</td>\n",
       "      <td>E01000024</td>\n",
       "      <td>Barking and Dagenham 008D</td>\n",
       "      <td>E02000009</td>\n",
       "      <td>Becontree West</td>\n",
       "      <td>E00000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176914</th>\n",
       "      <td>RM9 9LW</td>\n",
       "      <td>No</td>\n",
       "      <td>51.553494</td>\n",
       "      <td>0.141982</td>\n",
       "      <td>548600</td>\n",
       "      <td>186019</td>\n",
       "      <td>TQ485860</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>Parsloes</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - East and North East</td>\n",
       "      <td>Barking &amp; Dagenham and Havering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.6027</td>\n",
       "      <td>E01000065</td>\n",
       "      <td>Barking and Dagenham 007A</td>\n",
       "      <td>E02000008</td>\n",
       "      <td>Becontree East</td>\n",
       "      <td>E00000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176465</th>\n",
       "      <td>RM9 5YU</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.548682</td>\n",
       "      <td>0.127607</td>\n",
       "      <td>547619</td>\n",
       "      <td>185455</td>\n",
       "      <td>TQ476854</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>Parsloes</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - East and North East</td>\n",
       "      <td>Barking &amp; Dagenham and Havering</td>\n",
       "      <td>100024540,100024542,100024544,100024546,100024...</td>\n",
       "      <td>22.2117</td>\n",
       "      <td>E01000080</td>\n",
       "      <td>Barking and Dagenham 007C</td>\n",
       "      <td>E02000008</td>\n",
       "      <td>Becontree East</td>\n",
       "      <td>E00000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98748</th>\n",
       "      <td>IG11 8XF</td>\n",
       "      <td>No</td>\n",
       "      <td>51.545824</td>\n",
       "      <td>0.094561</td>\n",
       "      <td>545337</td>\n",
       "      <td>185071</td>\n",
       "      <td>TQ453850</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>Longbridge</td>\n",
       "      <td>...</td>\n",
       "      <td>London</td>\n",
       "      <td>Outer London - East and North East</td>\n",
       "      <td>Barking &amp; Dagenham and Havering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1216</td>\n",
       "      <td>E01000070</td>\n",
       "      <td>Barking and Dagenham 011D</td>\n",
       "      <td>E02000012</td>\n",
       "      <td>Longbridge &amp; Barking Park</td>\n",
       "      <td>E00000337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Postcode In Use?   Latitude  Longitude  Easting  Northing  Grid Ref  \\\n",
       "175870   RM8 3BA     Yes  51.555856   0.140103   548462    186278  TQ484862   \n",
       "175757   RM8 2RR     Yes  51.552265   0.117937   546937    185834  TQ469858   \n",
       "176914   RM9 9LW      No  51.553494   0.141982   548600    186019  TQ485860   \n",
       "176465   RM9 5YU     Yes  51.548682   0.127607   547619    185455  TQ476854   \n",
       "98748   IG11 8XF      No  51.545824   0.094561   545337    185071  TQ453850   \n",
       "\n",
       "                County              District        Ward  ...  \\\n",
       "175870  Greater London  Barking and Dagenham     Valence  ...   \n",
       "175757  Greater London  Barking and Dagenham   Becontree  ...   \n",
       "176914  Greater London  Barking and Dagenham    Parsloes  ...   \n",
       "176465  Greater London  Barking and Dagenham    Parsloes  ...   \n",
       "98748   Greater London  Barking and Dagenham  Longbridge  ...   \n",
       "\n",
       "       Travel To Work Area                         ITL level 2  \\\n",
       "175870              London  Outer London - East and North East   \n",
       "175757              London  Outer London - East and North East   \n",
       "176914              London  Outer London - East and North East   \n",
       "176465              London  Outer London - East and North East   \n",
       "98748               London  Outer London - East and North East   \n",
       "\n",
       "                            ITL level 3  \\\n",
       "175870  Barking & Dagenham and Havering   \n",
       "175757  Barking & Dagenham and Havering   \n",
       "176914  Barking & Dagenham and Havering   \n",
       "176465  Barking & Dagenham and Havering   \n",
       "98748   Barking & Dagenham and Havering   \n",
       "\n",
       "                                                    UPRNs Distance to sea  \\\n",
       "175870  100031158,100031159,100031160,100031161,100031...         21.8478   \n",
       "175757  100005702,100005704,100005706,100005707,100005...         22.9885   \n",
       "176914                                                NaN         21.6027   \n",
       "176465  100024540,100024542,100024544,100024546,100024...         22.2117   \n",
       "98748                                                 NaN         24.1216   \n",
       "\n",
       "       LSOA21 Code Lower layer super output area 2021 MSOA21 Code  \\\n",
       "175870   E01000102          Barking and Dagenham 007G   E02000008   \n",
       "175757   E01000024          Barking and Dagenham 008D   E02000009   \n",
       "176914   E01000065          Barking and Dagenham 007A   E02000008   \n",
       "176465   E01000080          Barking and Dagenham 007C   E02000008   \n",
       "98748    E01000070          Barking and Dagenham 011D   E02000012   \n",
       "\n",
       "        Middle layer super output area 2021  Census output area 2021  \n",
       "175870                       Becontree East                E00000508  \n",
       "175757                       Becontree West                E00000101  \n",
       "176914                       Becontree East                E00000318  \n",
       "176465                       Becontree East                E00000411  \n",
       "98748             Longbridge & Barking Park                E00000337  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stratified_postcode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f9441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ds SM_London_borough\n",
    "df_smLondon = pd.read_csv('/Users/ishanyash17/Downloads/SMLondon_Borough_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c400c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from boroughs to their specific postcodes\n",
    "borough_to_postcodes = {\n",
    "    'Barking and Dagenham': 'RM8 3BA',\n",
    "    'Barnet': 'NW11 8BW',\n",
    "    'Bexley': 'DA14 6BU',\n",
    "    'Brent': 'NW10 5FZ',\n",
    "    'Bromley': 'SE20 7ZR',\n",
    "    'Camden': 'NW3 1EP',\n",
    "    'Croydon': 'CR7 6ED',\n",
    "    'Ealing': 'UB5 9NB',\n",
    "    'Enfield': 'N11 3YY',\n",
    "    'Greenwich': 'SE18 1PQ',\n",
    "    'Hackney': 'E9 5AP',\n",
    "    'Hammersmith and Fulham': 'SW6 3XR',\n",
    "    'Haringey': 'N8 0BQ',\n",
    "    'Harrow': 'HA3 8RP',\n",
    "    'Havering': 'RM3 9AE',\n",
    "    'Hillingdon': 'HA5 2LH',\n",
    "    'Hounslow': 'TW5 9WS',\n",
    "    'Islington': 'N7 7HX',\n",
    "    'Kensington and Chelsea': 'SW3 5UP',\n",
    "    'Kingston upon Thames': 'KT2 7YR',\n",
    "    'Lambeth': 'SW3 9DZ',\n",
    "    'Lewisham': 'SE14 9DR',\n",
    "    'Merton': 'SW19 5DT',\n",
    "    'Newham': 'E15 2EG',\n",
    "    'Redbridge': 'IG1 8XD',\n",
    "    'Richmond upon Thames': 'TW10 6PT',\n",
    "    'Southwark': 'SE22 9JU',\n",
    "    'Sutton': 'SM2 6HB',\n",
    "    'Tower Hamlets': 'E1W 1AN',\n",
    "    'Waltham Forest': 'E17 5AU',\n",
    "    'Wandsworth': 'SW15 3XE',\n",
    "    'Westminster': 'W2 5BA'\n",
    "}\n",
    "\n",
    "# Assign the specific postcode to each borough in the dataset\n",
    "df_smLondon['postcode'] = df_smLondon['borough_name'].map(borough_to_postcodes)\n",
    "\n",
    "# Now, each block in df_merged has the specific postcode corresponding to its borough\n",
    "df_smLondon.to_csv(r'/Users/ishanyash17/Downloads/SMLondon_Borough_Pincode_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d85c6948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lad11Nm</th>\n",
       "      <th>Avg. Pop Den</th>\n",
       "      <th>Geometria</th>\n",
       "      <th>Latitude (generated)</th>\n",
       "      <th>Longitude (generated)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>177.951562</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>51.514641</td>\n",
       "      <td>-0.165308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>116.840223</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>51.451376</td>\n",
       "      <td>-0.182471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waltham Forest</td>\n",
       "      <td>98.720139</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>51.590104</td>\n",
       "      <td>-0.010848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>165.514583</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>51.516771</td>\n",
       "      <td>-0.037737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sutton</td>\n",
       "      <td>62.114050</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>51.365004</td>\n",
       "      <td>-0.180560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lad11Nm  Avg. Pop Den     Geometria  Latitude (generated)  \\\n",
       "0     Westminster    177.951562  MultiPolygon             51.514641   \n",
       "1      Wandsworth    116.840223  MultiPolygon             51.451376   \n",
       "2  Waltham Forest     98.720139  MultiPolygon             51.590104   \n",
       "3   Tower Hamlets    165.514583  MultiPolygon             51.516771   \n",
       "4          Sutton     62.114050  MultiPolygon             51.365004   \n",
       "\n",
       "   Longitude (generated)  \n",
       "0              -0.165308  \n",
       "1              -0.182471  \n",
       "2              -0.010848  \n",
       "3              -0.037737  \n",
       "4              -0.180560  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapsinfo = pd.read_csv('/Users/ishanyash17/Downloads/cleaned_data.csv')\n",
    "df_mapsinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "736a14e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Westminster',\n",
       " 'Wandsworth',\n",
       " 'Waltham Forest',\n",
       " 'Tower Hamlets',\n",
       " 'Sutton',\n",
       " 'Southwark',\n",
       " 'Richmond upon Thames',\n",
       " 'Redbridge',\n",
       " 'Newham',\n",
       " 'Merton',\n",
       " 'Lewisham',\n",
       " 'Lambeth',\n",
       " 'Kingston upon Thames',\n",
       " 'Kensington and Chelsea',\n",
       " 'Islington',\n",
       " 'Hounslow',\n",
       " 'Hillingdon',\n",
       " 'Havering',\n",
       " 'Harrow',\n",
       " 'Haringey',\n",
       " 'Hammersmith and Fulham',\n",
       " 'Hackney',\n",
       " 'Greenwich',\n",
       " 'Enfield',\n",
       " 'Ealing',\n",
       " 'Croydon',\n",
       " 'City of London',\n",
       " 'Camden',\n",
       " 'Bromley',\n",
       " 'Brent',\n",
       " 'Bexley',\n",
       " 'Barnet',\n",
       " 'Barking and Dagenham']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapsinfo['Lad11Nm'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24a48eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file_path = '/Users/ishanyash17/Downloads/London_Borough_ds.csv'\n",
    "output_file_path = '/Users/ishanyash17/Downloads/SMLondon_Borough_2013.csv'\n",
    "chunk_size = 100000\n",
    "\n",
    "first_chunk = True\n",
    "for chunk in pd.read_csv(input_file_path, chunksize=chunk_size, parse_dates=['tstp']):\n",
    "    chunk = chunk[chunk['tstp'].dt.year == 2013]\n",
    "\n",
    "    # Write each chunk to the CSV file\n",
    "    if first_chunk:\n",
    "        chunk.to_csv(output_file_path, index=False, mode='w', header=True)\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        chunk.to_csv(output_file_path, index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cacf94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
